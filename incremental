# Import necessary libraries
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# Load your dataset here
# Assuming X and y are your features and target variables
# Replace X and y with your own dataset
# Example:
# X, y = load_data()

# Split the data into train and test sets
X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize the data
scaler = StandardScaler()
X_train_full = scaler.fit_transform(X_train_full)
X_test = scaler.transform(X_test)

# Split the training data into parts for incremental learning
num_parts = 5  # Number of parts to divide the training data into
X_train_parts = np.array_split(X_train_full, num_parts)
y_train_parts = np.array_split(y_train_full, num_parts)

# Define the model
model = Sequential([
    Dense(64, activation='relu', input_shape=(X_train_full.shape[1],)),
    Dense(32, activation='relu'),
    Dense(16, activation='relu'),
    Dense(1)  # Output layer
])

# Compile the model
model.compile(optimizer='adam', loss='mse', metrics=['mae'])

# Incrementally train the model on each part
for i, (X_train_part, y_train_part) in enumerate(zip(X_train_parts, y_train_parts)):
    print(f"Training on part {i+1}/{num_parts}")
    model.fit(X_train_part, y_train_part, epochs=10, batch_size=16, verbose=1)

# Test the model on the hold-out test set
y_pred = model.predict(X_test)

# Calculate performance metrics
mse = mean_squared_error(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mse)

print(f"Mean Absolute Error (MAE): {mae:.2f}")
print(f"Mean Squared Error (MSE): {mse:.2f}")
print(f"Root Mean Squared Error (RMSE): {rmse:.2f}")
